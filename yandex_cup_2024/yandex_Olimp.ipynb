{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранжирование треков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoCGOvj_e5Us"
   },
   "source": [
    "### - загрузка и распаковка датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23202,
     "status": "ok",
     "timestamp": 1730746860114,
     "user": {
      "displayName": "Ilya Ya",
      "userId": "03342033783933917263"
     },
     "user_tz": -180
    },
    "id": "oeYUoNCYf2Uu",
    "outputId": "4d27dbd8-d540-4128-d086-4149f43faf46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7252,
     "status": "ok",
     "timestamp": 1730746873505,
     "user": {
      "displayName": "Ilya Ya",
      "userId": "03342033783933917263"
     },
     "user_tz": -180
    },
    "id": "ki4ZVcqxe5VR",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cc51ab2e-ba55-48d0-bd3d-aa001e1e57cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-4.0.0\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4W3j2SwxhDBp"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# temp_path = \"/content/sample_data\"\n",
    "# test_path =\"/content/drive/MyDrive/yandex_ml_olimp/data/test.zip\"\n",
    "# train_path =\"/content/drive/MyDrive/yandex_ml_olimp/data/train.zip\"\n",
    "drive_model_path =\"/content/drive/MyDrive/yandex_ml_olimp/models\"\n",
    "test_out_path =\"/content/drive/MyDrive/yandex_ml_olimp/outputs_test\"\n",
    "val_out_path  =\"/content/drive/MyDrive/yandex_ml_olimp/outputs_val\"\n",
    "splits_path = \"/content/drive/MyDrive/yandex_ml_olimp/splits\"\n",
    "tsv_path = \"/content/drive/MyDrive/yandex_ml_olimp/cliques2versions.tsv\"\n",
    "np_data_path = \"/content/drive/MyDrive/yandex_ml_olimp/splits/train_cliques.npy\"\n",
    "submission_name = f\"submission_{str(uuid.uuid4())}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioOc4Pp6mfFU"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "temp_dir = os.path.join(temp_path, \"data\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "temp_splits_dir = os.path.join(temp_dir, \"splits\")\n",
    "os.makedirs(temp_splits_dir, exist_ok=True)\n",
    "\n",
    "names = [\"test_ids.npy\", \"train_cliques.npy\", \"val_cliques.npy\"]\n",
    "for name in names:\n",
    "    src = os.path.join(splits_path, name)\n",
    "    dest = os.path.join(temp_splits_dir, name)\n",
    "    shutil.copy(src, dest)\n",
    "shutil.copy(tsv_path, temp_dir)\n",
    "\n",
    "os.makedirs(\"outputs_val\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31534,
     "status": "ok",
     "timestamp": 1730746916753,
     "user": {
      "displayName": "Ilya Ya",
      "userId": "03342033783933917263"
     },
     "user_tz": -180
    },
    "id": "2dkve-Iqhy4t",
    "outputId": "d64a895d-1dfd-4030-9304-092ebd3de54c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting...: 100%|██████████| 56281/56281 [00:27<00:00, 2010.04it/s]\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(test_path, 'r') as zf:\n",
    "    for mem in tqdm(zf.infolist(), desc=\"Extracting...\"):\n",
    "        try:\n",
    "            zf.extract(mem, temp_dir)\n",
    "        except Exception as e:\n",
    "            print(\"Extracting error:\", e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167827,
     "status": "ok",
     "timestamp": 1730747280219,
     "user": {
      "displayName": "Ilya Ya",
      "userId": "03342033783933917263"
     },
     "user_tz": -180
    },
    "id": "EfHfRmbvW7yo",
    "outputId": "e088127a-0043-4497-ffe2-498e630114be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting...: 100%|██████████| 316050/316050 [02:42<00:00, 1939.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path =\"/content/drive/MyDrive/yandex_ml_olimp/data/train.zip\"\n",
    "\n",
    "with ZipFile(train_path, 'r') as zf:\n",
    "    for mem in tqdm(zf.infolist(), desc=\"Extracting...\"):\n",
    "        try:\n",
    "            zf.extract(mem, temp_dir)\n",
    "        except Exception as e:\n",
    "            print(\"Extracting error:\", e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Основные импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOEW_Gz_mGAn"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "from typing import Dict, List, Literal, Tuple\n",
    "\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import pairwise_distances, pairwise_distances_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmtflPkwmYVy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Дополнительные структуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtjwRVNlnj1T"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from yaml import FullLoader, load, safe_load\n",
    "\n",
    "@dataclass\n",
    "class bcolors:\n",
    "    OKGREEN: str = \"\\033[92m\"\n",
    "    WARNING: str = \"\\033[93m\"\n",
    "    FAIL: str = \"\\033[91m\"\n",
    "    ENDC: str = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def load_config(config_path: str) -> Dict:\n",
    "    with open(config_path) as file:\n",
    "        config = safe_load(file)\n",
    "\n",
    "    if config[\"device\"] == \"gpu\":\n",
    "        config[\"device\"] = \"cuda:0\"\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlkkYF27nHAM"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class ValDict(TypedDict):\n",
    "    anchor_id: int\n",
    "    f_t: torch.Tensor\n",
    "    f_c: torch.Tensor\n",
    "\n",
    "\n",
    "class BatchDict(TypedDict):\n",
    "    anchor_id: int\n",
    "    anchor: torch.Tensor\n",
    "    anchor_label: torch.Tensor\n",
    "    positive_id: int\n",
    "    positive: torch.Tensor\n",
    "    negative_id: int\n",
    "    negative: torch.Tensor\n",
    "\n",
    "\n",
    "class Postfix(TypedDict):\n",
    "    Epoch: int\n",
    "    train_loss: float\n",
    "    train_loss_step: float\n",
    "    train_cls_loss: float\n",
    "    train_cls_loss_step: float\n",
    "    train_triplet_loss: float\n",
    "    train_triplet_loss_step: float\n",
    "    val_loss: float\n",
    "    mr1: float\n",
    "    mAP: float\n",
    "\n",
    "\n",
    "class TestResults(TypedDict):\n",
    "    test_mr1: float\n",
    "    test_mAP: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Вспомогательные функции "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwuyghLharn0"
   },
   "outputs": [],
   "source": [
    "def get_cls_weights(df:pd.DataFrame)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Посчитать веса классов для кросс-энтропии\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df2 = df[\"versions\"].apply(pd.Series)\n",
    "    df2.index=df.set_index(\"clique\").index\n",
    "    df2=df2.stack().reset_index(\"clique\")\n",
    "    df2=df2.rename(columns={0:\"track_id\"}).astype(\"int32\")\n",
    "    df2[\"count\"]=df2.groupby(df2[\"clique\"]).transform(\"count\")\n",
    "\n",
    "    df2=df2.drop(columns=[\"track_id\"])\n",
    "    df2=df2.drop_duplicates(keep=\"first\")\n",
    "    weights = {k:v for k, v in zip(df2[\"clique\"], df2[\"count\"])}\n",
    "    w=list(sorted(list(weights.items()), key=lambda el: el[0]))\n",
    "    w=np.array([el[0] for el in w])\n",
    "    w=(w-w.min())/w.max()\n",
    "    return w\n",
    "\n",
    "def read_df(data_path=\"\", np_data_path=\"\"):\n",
    "    '''Считывание датасета'''\n",
    "    cliques_subset = np.load(\n",
    "        np_data_path\n",
    "    )\n",
    "\n",
    "    versions = pd.read_csv(\n",
    "        data_path,\n",
    "        sep=\"\\t\",\n",
    "        converters={\"versions\": eval},\n",
    "    )\n",
    "\n",
    "    versions = versions[\n",
    "        versions[\"clique\"].isin(set(cliques_subset))\n",
    "    ]\n",
    "    mapping = {}\n",
    "    for k, clique in enumerate(sorted(cliques_subset)):\n",
    "        mapping[clique] = k\n",
    "    versions[\"clique\"] = versions[\"clique\"].map(lambda x: mapping[x])\n",
    "    versions.set_index(\"clique\", inplace=False)\n",
    "\n",
    "    return versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Датасет и даталоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdaBxBAFm14f"
   },
   "outputs": [],
   "source": [
    "class CoverDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        file_ext: str,\n",
    "        dataset_path: str,\n",
    "        data_split: Literal[\"train\", \"val\", \"test\"],\n",
    "        debug: bool,\n",
    "        max_len: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.file_ext = file_ext\n",
    "        self.dataset_path = dataset_path\n",
    "        self.data_split = data_split\n",
    "        self.debug = debug\n",
    "        self.max_len = max_len\n",
    "        self._load_data()\n",
    "        self.rnd_indices = np.random.permutation(len(self.track_ids))\n",
    "        self.current_index = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.track_ids)\n",
    "\n",
    "    def __getitem__(self, index: int) -> BatchDict:\n",
    "        track_id = self.track_ids[index]\n",
    "        anchor_cqt = self._load_cqt(track_id)\n",
    "\n",
    "        if self.data_split == \"train\":\n",
    "            clique_id = self.version2clique.loc[track_id, \"clique\"]\n",
    "            pos_id, neg_id = self._triplet_sampling(track_id, clique_id)\n",
    "            positive_cqt = self._load_cqt(pos_id)\n",
    "            negative_cqt = self._load_cqt(neg_id)\n",
    "        else:\n",
    "            clique_id = -1\n",
    "            pos_id = torch.empty(0)\n",
    "            positive_cqt = torch.empty(0)\n",
    "            neg_id = torch.empty(0)\n",
    "            negative_cqt = torch.empty(0)\n",
    "        return dict(\n",
    "            anchor_id=track_id,\n",
    "            anchor=anchor_cqt,\n",
    "            anchor_label=torch.tensor(clique_id, dtype=torch.float),\n",
    "            positive_id=pos_id,\n",
    "            positive=positive_cqt,\n",
    "            negative_id=neg_id,\n",
    "            negative=negative_cqt,\n",
    "        )\n",
    "\n",
    "    def _make_file_path(self, track_id, file_ext):\n",
    "        a = track_id % 10\n",
    "        b = track_id // 10 % 10\n",
    "        c = track_id // 100 % 10\n",
    "        return os.path.join(str(c), str(b), str(a), f\"{track_id}.{file_ext}\")\n",
    "\n",
    "    def _triplet_sampling(self, track_id: int, clique_id: int) -> Tuple[int, int]:\n",
    "        versions = self.versions.loc[clique_id, \"versions\"]\n",
    "        pos_list = np.setdiff1d(versions, track_id)\n",
    "        pos_id = np.random.choice(pos_list, 1)[0]\n",
    "        if self.current_index >= len(self.rnd_indices):\n",
    "            self.current_index = 0\n",
    "            self.rnd_indices = np.random.permutation(len(self.track_ids))\n",
    "        neg_id = self.track_ids[self.rnd_indices[self.current_index]]\n",
    "        self.current_index += 1\n",
    "        while neg_id in versions:\n",
    "            if self.current_index >= len(self.rnd_indices):\n",
    "                self.current_index = 0\n",
    "                self.rnd_indices = np.random.permutation(len(self.track_ids))\n",
    "            neg_id = self.track_ids[self.rnd_indices[self.current_index]]\n",
    "            self.current_index += 1\n",
    "        return (pos_id, neg_id)\n",
    "\n",
    "    def _load_data(self) -> None:\n",
    "        if self.data_split in [\"train\", \"val\"]:\n",
    "            cliques_subset = np.load(\n",
    "                os.path.join(\n",
    "                    self.data_path, \"splits\", \"{}_cliques.npy\".format(self.data_split)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.versions = pd.read_csv(\n",
    "                os.path.join(self.data_path, \"cliques2versions.tsv\"),\n",
    "                sep=\"\\t\",\n",
    "                converters={\"versions\": eval},\n",
    "            )\n",
    "            self.versions = self.versions[\n",
    "                self.versions[\"clique\"].isin(set(cliques_subset))\n",
    "            ]\n",
    "            mapping = {}\n",
    "            for k, clique in enumerate(sorted(cliques_subset)):\n",
    "                mapping[clique] = k\n",
    "            self.versions[\"clique\"] = self.versions[\"clique\"].map(lambda x: mapping[x])\n",
    "            self.versions.set_index(\"clique\", inplace=True)\n",
    "            self.version2clique = pd.DataFrame(\n",
    "                [\n",
    "                    {\"version\": version, \"clique\": clique}\n",
    "                    for clique, row in self.versions.iterrows()\n",
    "                    for version in row[\"versions\"]\n",
    "                ]\n",
    "            ).set_index(\"version\")\n",
    "            self.track_ids = self.version2clique.index.to_list()\n",
    "\n",
    "        else:\n",
    "            self.track_ids = np.load(\n",
    "                os.path.join(\n",
    "                    self.data_path, \"splits\", \"{}_ids.npy\".format(self.data_split)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _load_cqt(self, track_id: str) -> torch.Tensor:\n",
    "        filename = os.path.join(\n",
    "            self.dataset_path, self._make_file_path(track_id, self.file_ext)\n",
    "        )\n",
    "        cqt_spectrogram = np.load(filename)\n",
    "        return torch.from_numpy(cqt_spectrogram)\n",
    "\n",
    "\n",
    "def cover_dataloader(\n",
    "    data_path: str,\n",
    "    file_ext: str,\n",
    "    dataset_path: str,\n",
    "    data_split: Literal[\"train\", \"val\", \"test\"],\n",
    "    debug: bool,\n",
    "    max_len: int,\n",
    "    batch_size: int,\n",
    "    **config: Dict,\n",
    ") -> DataLoader:\n",
    "    return DataLoader(\n",
    "        CoverDataset(\n",
    "            data_path, file_ext, dataset_path, data_split, debug, max_len=max_len\n",
    "        ),\n",
    "        batch_size=batch_size if max_len > 0 else 1,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        shuffle=config[\"shuffle\"],\n",
    "        drop_last=config[\"drop_last\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Еще вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PZ8GGuXn-GE"
   },
   "outputs": [],
   "source": [
    "def reduce_func(D_chunk, start):\n",
    "    top_size = 100\n",
    "    nearest_items = np.argsort(D_chunk, axis=1)[:, : top_size + 1]\n",
    "    return [(i, items[items != i]) for i, items in enumerate(nearest_items, start)]\n",
    "\n",
    "\n",
    "def dataloader_factory(config: Dict, data_split: str) -> DataLoader:\n",
    "    return cover_dataloader(\n",
    "        data_path=config[\"data_path\"],\n",
    "        file_ext=config[\"file_extension\"],\n",
    "        # dataset_path=config[data_split][\"dataset_path\"],\n",
    "        data_split=data_split,\n",
    "        debug=config[\"debug\"],\n",
    "        max_len=50,\n",
    "        **config[data_split],\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_ranking_metrics(\n",
    "    embeddings: np.ndarray, cliques: List[int]\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    distances = pairwise_distances(embeddings)\n",
    "    s_distances = np.argsort(distances, axis=1)\n",
    "    cliques = np.array(cliques)\n",
    "    query_cliques = cliques[s_distances[:, 0]]\n",
    "    search_cliques = cliques[s_distances[:, 1:]]\n",
    "\n",
    "    query_cliques = np.tile(query_cliques, (search_cliques.shape[-1], 1)).T\n",
    "    mask = np.equal(search_cliques, query_cliques)\n",
    "\n",
    "    ranks = 1.0 / (mask.argmax(axis=1) + 1.0)\n",
    "\n",
    "    cumsum = np.cumsum(mask, axis=1)\n",
    "    mask2 = mask * cumsum\n",
    "    mask2 = mask2 / np.arange(1, mask2.shape[-1] + 1)\n",
    "    average_precisions = np.sum(mask2, axis=1) / np.sum(mask, axis=1)\n",
    "\n",
    "    return (ranks, average_precisions)\n",
    "\n",
    "\n",
    "def dir_checker(output_dir: str) -> str:\n",
    "    output_dir = re.sub(r\"run-[0-9]+/*\", \"\", output_dir)\n",
    "    runs = glob.glob(os.path.join(output_dir, \"run-*\"))\n",
    "    if runs != []:\n",
    "        max_run = max(map(lambda x: int(x.split(\"-\")[-1]), runs))\n",
    "        run = max_run + 1\n",
    "    else:\n",
    "        run = 0\n",
    "    outdir = os.path.join(output_dir, f\"run-{run}\")\n",
    "    return outdir\n",
    "\n",
    "\n",
    "def save_test_predictions(predictions: List, output_dir: str) -> None:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(os.path.join(output_dir, submission_name), \"w\") as foutput:\n",
    "        for query_item, query_nearest in predictions:\n",
    "            foutput.write(\n",
    "                \"{} {}\\n\".format(int(query_item), \" \".join(map(str, list(map(int, query_nearest)))))\n",
    "            )\n",
    "    #TODO: добавить копирование на диск\n",
    "    sub_path = f\"/content/outputs_test/{submission_name}\"\n",
    "    shutil.copy(sub_path, test_out_path)\n",
    "\n",
    "\n",
    "def save_predictions(outputs: Dict[str, np.ndarray], output_dir: str) -> None:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for key in outputs:\n",
    "        if \"_ids\" in key:\n",
    "            with jsonlines.open(os.path.join(output_dir, f\"{key}.jsonl\"), \"w\") as f:\n",
    "                if len(outputs[key][0]) == 4:\n",
    "                    for clique, anchor, pos, neg in outputs[key]:\n",
    "                        f.write(\n",
    "                            {\n",
    "                                \"clique_id\": clique,\n",
    "                                \"anchor_id\": anchor,\n",
    "                                \"positive_id\": pos,\n",
    "                                \"negative_id\": neg,\n",
    "                            }\n",
    "                        )\n",
    "                else:\n",
    "                    for clique, anchor in outputs[key]:\n",
    "                        f.write({\"clique_id\": clique, \"anchor_id\": anchor})\n",
    "        else:\n",
    "            np.save(os.path.join(output_dir, f\"{key}.npy\"), outputs[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Дополнительные структуры для ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUTkauk1nVDy"
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(\n",
    "            1.0 / p\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(p={self.p.data.tolist()[0]:.4f}, eps={str(self.eps)})\"\n",
    "\n",
    "\n",
    "class IBN(nn.Module):\n",
    "    r\"\"\"Instance-Batch Normalization layer from\n",
    "    `\"Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net\"\n",
    "    <https://arxiv.org/pdf/1807.09441.pdf>`\n",
    "    Args:\n",
    "        planes (int): Number of channels for the input tensor\n",
    "        ratio (float): Ratio of instance normalization in the IBN layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, planes, ratio):\n",
    "        super(IBN, self).__init__()\n",
    "        self.half = int(planes * ratio)\n",
    "        self.IN = nn.InstanceNorm2d(self.half, affine=True)\n",
    "        self.BN = nn.BatchNorm2d(planes - self.half)\n",
    "\n",
    "    def forward(self, x):\n",
    "        split = torch.split(x, self.half, 1)\n",
    "        out1 = self.IN(split[0].contiguous())\n",
    "        out2 = self.BN(split[1].contiguous())\n",
    "        out = torch.cat((out1, out2), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Класс Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl9tmSg4mgz6"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        last: bool = False,\n",
    "        downsample=None,\n",
    "        stride=1,\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias\n",
    "        )\n",
    "        if not last:\n",
    "            # Apply Instance normalization in first half channels (ratio=0.5)\n",
    "            self.ibn = IBN(out_channels, ratio=0.5)\n",
    "        else:\n",
    "            self.ibn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        residual = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.ibn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        out = residual + x\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Resnet50\n",
    "*Эту архитектуру создатели предложили в качестве baseline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGrveZbHmQ8i"
   },
   "outputs": [],
   "source": [
    "class Resnet50(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ResBlock: Bottleneck,\n",
    "        emb_dim: int = 2048,\n",
    "        num_channels: int = 1,\n",
    "        num_classes: int = 8858,\n",
    "        dropout=0.1,\n",
    "        n_bins=84,\n",
    "    ) -> None:\n",
    "\n",
    "        super(Resnet50, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, blocks=3, planes=64, stride=1)\n",
    "        self.layer2 = self._make_layer(ResBlock, blocks=4, planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, blocks=6, planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(\n",
    "            ResBlock, blocks=3, planes=512, stride=1, last=True\n",
    "        )\n",
    "\n",
    "        self.gem_pool = GeM()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.bn_fc = nn.BatchNorm1d(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, num_classes, bias=False)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        ResBlock: Bottleneck,\n",
    "        blocks: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        last: bool = False,\n",
    "    ):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != planes * ResBlock.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    planes * ResBlock.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(planes * ResBlock.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            ResBlock(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=planes,\n",
    "                stride=stride,\n",
    "                downsample=downsample,\n",
    "                last=last,\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = planes * ResBlock.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                ResBlock(in_channels=self.in_channels, out_channels=planes, last=last)\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Unsqueeze to simulate 1-channel image\n",
    "        x = self.conv1(x.unsqueeze(1))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        f_t = self.gem_pool(x)\n",
    "        f_t = self.dropout(torch.flatten(f_t, start_dim=1))\n",
    "\n",
    "        f_c = self.bn_fc(f_t)\n",
    "        cls = self.fc(f_c)\n",
    "\n",
    "        return dict(f_t=f_t, f_c=f_c, cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Трансформер ViT\n",
    "Попытка поменять модель на видеотрансформер. Выбила 0.2 скор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw3Aavmydxj1"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16\n",
    "from functools import partial\n",
    "from torchvision.models.vision_transformer import Encoder\n",
    "from typing import Callable\n",
    "\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model,\n",
    "        hidden_dim=768,\n",
    "        emb_dim=2048,\n",
    "        num_classes=39553):\n",
    "\n",
    "        self.image_size = 64\n",
    "        super(MyViT, self).__init__()\n",
    "\n",
    "        # скелет\n",
    "        self.pretrained = pretrained_model\n",
    "\n",
    "        # голова\n",
    "        self.pretrained.conv_proj = nn.Conv2d(\n",
    "            1, hidden_dim, kernel_size=(8, 8), stride=(8, 8)\n",
    "        )\n",
    "\n",
    "        # основа\n",
    "        patch_size = 8\n",
    "        dropout =0.05\n",
    "        attention_dropout = 0.05\n",
    "        norm_layer: Callable[..., torch.nn.Module] = partial(nn.LayerNorm, eps=1e-6)\n",
    "\n",
    "\n",
    "        self.pretrained.patch_size = patch_size\n",
    "        seq_length = (self.image_size // self.pretrained.patch_size) ** 2 + 1\n",
    "\n",
    "        self.pretrained.encoder = Encoder(\n",
    "            seq_length=seq_length,\n",
    "            num_layers = 4,\n",
    "            num_heads=12,\n",
    "            hidden_dim=768,\n",
    "            mlp_dim = 3072,\n",
    "            dropout=dropout,\n",
    "            attention_dropout=attention_dropout,\n",
    "            norm_layer=norm_layer)\n",
    "\n",
    "\n",
    "        self.pretrained.encoder.pos_embedding = nn.Parameter(\n",
    "            torch.empty(1, seq_length, hidden_dim).normal_(std=0.02)\n",
    "        )\n",
    "\n",
    "        self.pretrained.heads.head = nn.Linear(\n",
    "            in_features=hidden_dim, out_features=emb_dim, bias=True\n",
    "        )\n",
    "\n",
    "        self.bn_fc = nn.BatchNorm1d(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, num_classes, bias=False)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = nn.functional.interpolate(x, size=(self.image_size, self.image_size)).to(\n",
    "            dtype=torch.float) # Было torch.bfloat16\n",
    "        f_t = self.pretrained(x)\n",
    "        # f_c = self.bn_fc(f_t)\n",
    "        # cls = self.fc(f_c)\n",
    "        cls = self.fc(f_е)\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoo4Agx1w0T7"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_32\n",
    "from functools import partial\n",
    "from torchvision.models.vision_transformer import Encoder\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "        pretrained_model,\n",
    "        hidden_dim=768,\n",
    "        emb_dim=2048,\n",
    "        num_classes=39553):\n",
    "\n",
    "        self.image_size = 224\n",
    "        super(MyTransformer, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.pretrained.head = nn.Identity()\n",
    "        self.new_head = nn.Sequential(\n",
    "            nn.Linear(1000, emb_dim),\n",
    "        )\n",
    "        self.bn_fc = nn.BatchNorm1d(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, num_classes, bias=False)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = torch.cat([x, x, x], dim =1)\n",
    "        x = nn.functional.interpolate(x, size=(self.image_size, self.image_size)).to(\n",
    "            dtype=torch.float)\n",
    "        x = self.pretrained(x)\n",
    "        f_t = self.new_head(x)\n",
    "        f_c = self.bn_fc(f_t)\n",
    "        cls = self.fc(f_c)\n",
    "        return dict(f_t=f_t, f_c=f_c, cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ResNet18\n",
    "Попытка поменять модель на облегченный resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW7If2bbZfzK"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        hidden_dim = 512\n",
    "        emb_dim = 512\n",
    "        num_classes = 39535\n",
    "        self.image_size = 64\n",
    "        self.resnet = resnet18(weights=None)\n",
    "        self.resnet.fc=nn.Linear(in_features=hidden_dim, out_features=emb_dim, bias=True)\n",
    "        self.bn_fc = nn.BatchNorm1d(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, num_classes, bias=False)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "    def forward(self, x):\n",
    "        x=x.unsqueeze(1)\n",
    "        x=nn.functional.interpolate(x, size=(self.image_size, self.image_size))#.to(dtype=torch.float32, device=device)\n",
    "        x=torch.cat([x, x, x], dim =1)\n",
    "        f_t = self.resnet(x)\n",
    "        f_c = self.bn_fc(f_t)\n",
    "        cls=self.fc(f_c)\n",
    "        return dict(f_t=f_t, f_c=f_c, cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACC0pKeKovWf"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience: int = 1, delta: int = 0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.max_validation_mAP = -np.inf\n",
    "\n",
    "    def __call__(self, validation_mAP) -> bool:\n",
    "        if validation_mAP > self.max_validation_mAP:\n",
    "            self.max_validation_mAP = validation_mAP\n",
    "            self.counter = 0\n",
    "        elif validation_mAP <= (self.max_validation_mAP - self.delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Основной пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNGzmR-Kj98g"
   },
   "outputs": [],
   "source": [
    "class TrainModule:\n",
    "    def __init__(self, config: Dict) -> None:\n",
    "        self.config = config\n",
    "        self.state = \"initializing\"\n",
    "        self.best_model_path: str = None\n",
    "        self.num_classes = self.config[\"train\"][\n",
    "            \"num_classes\"\n",
    "        ]  # (39535,) Количество входных классов\n",
    "        self.max_len = 50\n",
    "\n",
    "        #self.model = Resnet50(\n",
    "        #    Bottleneck,\n",
    "        #    num_channels=self.config[\"num_channels\"],\n",
    "        #    num_classes=self.num_classes,\n",
    "        #    dropout=self.config[\"train\"][\"dropout\"]\n",
    "        #)\n",
    "        # self.model.to(self.config[\"device\"])\n",
    "        # os.environ['TORCH_HOME'] = 'models'\n",
    "        # self.model = vit_b_32(pretrained=True, image_size=224)\n",
    "        # self.model = MyTransformer(\n",
    "        #      self.model,\n",
    "        #      num_classes=self.config[\"train\"][\"num_classes\"])\n",
    "        # self.model = self.model.to(dtype=torch.float, device=config[\"device\"])\n",
    "        # print(self.model)\n",
    "\n",
    "        # My VT 4 blocks\n",
    "        #self.model = vit_b_16(pretrained=False, image_size=64)\n",
    "        #self.model = MyViT(\n",
    "        #     self.model,\n",
    "        #     num_classes=self.config[\"train\"][\"num_classes\"])\n",
    "        #self.model = self.model.to(dtype=torch.float, device=config[\"device\"])\n",
    "        #print(self.model)\n",
    "        self.model = ResNet18().to(device=config[\"device\"])\n",
    "\n",
    "\n",
    "\n",
    "        self.postfix: Postfix = {}\n",
    "\n",
    "        # self.triplet_loss = nn.TripletMarginLoss(margin=config[\"train\"][\"triplet_margin\"])\n",
    "        self.triplet_loss = nn.TripletMarginWithDistanceLoss(\n",
    "            distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y),\n",
    "            margin=config[\"train\"][\"triplet_margin\"],\n",
    "        )\n",
    "        #TODO: возможно, сюда стоит добавить взвешенные классы?\n",
    "        np_weights = get_cls_weights(read_df(tsv_path, np_data_path))\n",
    "        weight = torch.from_numpy(np_weights).to(dtype=torch.float32, device=self.config[\"device\"])\n",
    "\n",
    "        self.cls_loss = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            label_smoothing=config[\"train\"][\"smooth_factor\"]\n",
    "        )\n",
    "\n",
    "        self.early_stop = EarlyStopper(patience=self.config[\"train\"][\"patience\"])\n",
    "        self.optimizer = self.configure_optimizers()\n",
    "        #\n",
    "        # self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "        if self.config[\"device\"] != \"cpu\":\n",
    "            # self.scaler = torch.cuda.amp.GradScaler(enabled=self.config[\"train\"][\"mixed_precision\"])\n",
    "            self.scaler = torch.cuda.amp.GradScaler(\n",
    "                enabled=self.config[\"train\"][\"mixed_precision\"]\n",
    "            )\n",
    "\n",
    "    def pipeline(self) -> None:\n",
    "        self.config[\"val\"][\"output_dir\"] = dir_checker(self.config[\"val\"][\"output_dir\"])\n",
    "\n",
    "        if self.config[\"train\"][\"model_ckpt\"] is not None:\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.config[\"train\"][\"model_ckpt\"]), strict=False\n",
    "            )\n",
    "            print(f'Model loaded from checkpoint: {self.config[\"train\"][\"model_ckpt\"]}')\n",
    "\n",
    "        self.t_loader = dataloader_factory(config=self.config, data_split=\"train\")\n",
    "        self.v_loader = dataloader_factory(config=self.config, data_split=\"val\")\n",
    "        self.state = \"running\"\n",
    "\n",
    "        self.pbar = trange(\n",
    "            self.config[\"train\"][\"epochs\"],\n",
    "            disable=(not self.config[\"progress_bar\"]),\n",
    "            position=0,\n",
    "            leave=True,\n",
    "        )\n",
    "        for epoch in self.pbar:\n",
    "            if self.state in [\"early_stopped\", \"interrupted\", \"finished\"]:\n",
    "                return\n",
    "\n",
    "            self.postfix[\"Epoch\"] = epoch\n",
    "            self.pbar.set_postfix(self.postfix)\n",
    "\n",
    "            try:\n",
    "                # pass\n",
    "                self.train_procedure()\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nKeyboard Interrupt detected. Attempting gracefull shutdown...\")\n",
    "                self.state = \"interrupted\"\n",
    "            except Exception as err:\n",
    "                raise (err)\n",
    "\n",
    "            '''\n",
    "            if self.state == \"interrupted\":\n",
    "                self.validation_procedure()\n",
    "                self.pbar.set_postfix(\n",
    "                    {\n",
    "                        k: self.postfix[k]\n",
    "                        for k in self.postfix.keys() & {\"train_loss_step\", \"mr1\", \"mAP\"}\n",
    "                    }\n",
    "                )\n",
    "            '''\n",
    "\n",
    "        self.state = \"finished\"\n",
    "\n",
    "    def validate(self) -> None:\n",
    "        self.v_loader = dataloader_factory(config=self.config, data_split=\"val\")\n",
    "        self.state = \"running\"\n",
    "        self.validation_procedure()\n",
    "        self.state = \"finished\"\n",
    "\n",
    "    def test(self) -> None:\n",
    "        self.test_loader = dataloader_factory(config=self.config, data_split=\"test\")\n",
    "        self.test_results: TestResults = {}\n",
    "\n",
    "        if self.best_model_path is not None:\n",
    "            self.model.load_state_dict(torch.load(self.best_model_path), strict=False)\n",
    "            print(f\"Best models loaded from checkpoint: {self.best_model_path}\")\n",
    "        elif self.config[\"test\"][\"model_ckpt\"] is not None:\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.config[\"test\"][\"model_ckpt\"], map_location=torch.device(self.config[\"device\"])), strict=False\n",
    "            )\n",
    "            print(f'Model loaded from checkpoint: {self.config[\"test\"][\"model_ckpt\"]}')\n",
    "        elif self.state == \"initializing\":\n",
    "            print(\"Warning: Testing with random weights\")\n",
    "\n",
    "        self.model=self.model.to(dtype=torch.float)\n",
    "\n",
    "        self.state = \"running\"\n",
    "        self.test_procedure()\n",
    "        self.state = \"finished\"\n",
    "\n",
    "    def train_procedure(self) -> None:\n",
    "        self.model.train()\n",
    "        train_loss_list = []\n",
    "        train_cls_loss_list = []\n",
    "        train_triplet_loss_list = []\n",
    "        self.max_len = self.t_loader.dataset.max_len\n",
    "        for step, batch in tqdm(\n",
    "            enumerate(self.t_loader),\n",
    "            total=len(self.t_loader),\n",
    "            disable=(not self.config[\"progress_bar\"]),\n",
    "            position=2,\n",
    "            leave=False,\n",
    "        ):\n",
    "            train_step = self.training_step(batch)\n",
    "            self.postfix[\"train_loss_step\"] = float(\n",
    "                f\"{train_step['train_loss_step']:.3f}\"\n",
    "            )\n",
    "            train_loss_list.append(train_step[\"train_loss_step\"])\n",
    "            self.postfix[\"train_cls_loss_step\"] = float(\n",
    "                f\"{train_step['train_cls_loss']:.3f}\"\n",
    "            )\n",
    "            train_cls_loss_list.append(train_step[\"train_cls_loss\"])\n",
    "            self.postfix[\"train_triplet_loss_step\"] = float(\n",
    "                f\"{train_step['train_triplet_loss']:.3f}\"\n",
    "            )\n",
    "            train_triplet_loss_list.append(train_step[\"train_triplet_loss\"])\n",
    "            self.pbar.set_postfix(\n",
    "                {\n",
    "                    k: self.postfix[k]\n",
    "                    for k in self.postfix.keys() & {\"train_loss_step\", \"mr1\", \"mAP\"}\n",
    "                }\n",
    "            )\n",
    "        train_loss = torch.tensor(train_loss_list)\n",
    "        train_cls_loss = torch.tensor(train_cls_loss_list)\n",
    "        train_triplet_loss = torch.tensor(train_triplet_loss_list)\n",
    "        self.postfix[\"train_loss\"] = train_loss.mean().item()\n",
    "        self.postfix[\"train_cls_loss\"] = train_cls_loss.mean().item()\n",
    "        self.postfix[\"train_triplet_loss\"] = train_triplet_loss.mean().item()\n",
    "\n",
    "        self.best_model_path = os.path.join(drive_model_path, f\"best-resnet18_{str(uuid.uuid4())}.pt\")\n",
    "        torch.save(deepcopy(self.model.state_dict()), self.best_model_path)\n",
    "\n",
    "        #self.validation_procedure()\n",
    "        #self.overfit_check()\n",
    "        self.pbar.set_postfix(\n",
    "            {\n",
    "                k: self.postfix[k]\n",
    "                for k in self.postfix.keys() & {\"train_loss_step\", \"mr1\", \"mAP\"}\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch: BatchDict) -> Dict[str, float]:\n",
    "        with torch.autocast(\n",
    "            device_type=self.config[\"device\"].split(\":\")[0],\n",
    "            enabled=self.config[\"train\"][\"mixed_precision\"],\n",
    "        ):\n",
    "            anchor = self.model.forward(batch[\"anchor\"].to(self.config[\"device\"]))\n",
    "            positive = self.model.forward(batch[\"positive\"].to(self.config[\"device\"]))\n",
    "            negative = self.model.forward(batch[\"negative\"].to(self.config[\"device\"]))\n",
    "            l1 = self.triplet_loss(anchor[\"f_t\"], positive[\"f_t\"], negative[\"f_t\"])\n",
    "            labels = nn.functional.one_hot(\n",
    "                batch[\"anchor_label\"].long(), num_classes=self.num_classes\n",
    "            )\n",
    "            l2 = 0.1* self.cls_loss(anchor[\"cls\"], labels.float().to(self.config[\"device\"]))\n",
    "            loss = l1 + l2\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        if self.config[\"device\"] != \"cpu\":\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        # self.scheduler.step()\n",
    "\n",
    "        return {\n",
    "            \"train_loss_step\": loss.item(),\n",
    "            \"train_triplet_loss\": l1.item(),\n",
    "            \"train_cls_loss\": l2.item(),\n",
    "        }\n",
    "\n",
    "    def validation_procedure(self) -> None:\n",
    "        print(\"start val proc\")\n",
    "        self.model.eval()\n",
    "        embeddings: Dict[int, torch.Tensor] = {}\n",
    "        for batch in tqdm(\n",
    "            self.v_loader,\n",
    "            disable=(not self.config[\"progress_bar\"]),\n",
    "            position=1,\n",
    "            leave=False,\n",
    "        ):\n",
    "            val_dict = self.validation_step(batch)\n",
    "            # print(val_dict)\n",
    "            if val_dict[\"f_t\"].ndim == 1:\n",
    "                val_dict[\"f_c\"] = val_dict[\"f_c\"].unsqueeze(0)\n",
    "                val_dict[\"f_t\"] = val_dict[\"f_t\"].unsqueeze(0)\n",
    "            for anchor_id, triplet_embedding, embedding in zip(\n",
    "                val_dict[\"anchor_id\"], val_dict[\"f_t\"], val_dict[\"f_c\"]\n",
    "            ):\n",
    "                embeddings[anchor_id] = torch.stack([triplet_embedding, embedding])\n",
    "\n",
    "        val_outputs = self.validation_epoch_end(embeddings)\n",
    "        print(\n",
    "            f\"\\n{' Validation Results ':=^50}\\n\"\n",
    "            + \"\\n\".join([f'\"{key}\": {value}' for key, value in self.postfix.items()])\n",
    "            + f\"\\n{' End of Validation ':=^50}\\n\"\n",
    "        )\n",
    "\n",
    "        if self.config[\"val\"][\"save_val_outputs\"]:\n",
    "            val_outputs[\"val_embeddings\"] = torch.stack(list(embeddings.values()))[\n",
    "                :, 1\n",
    "            ].numpy()\n",
    "            save_predictions(val_outputs, output_dir=self.config[\"val\"][\"output_dir\"])\n",
    "        self.model.train()\n",
    "\n",
    "    def validation_epoch_end(\n",
    "        self, outputs: Dict[int, torch.Tensor]\n",
    "    ) -> Dict[int, np.ndarray]:\n",
    "        print(\"validation_epoch_end\")\n",
    "        # val_loss = torch.zeros(len(outputs))\n",
    "        # pos_ids = []\n",
    "        # neg_ids = []\n",
    "        clique_ids = []\n",
    "        for k, (anchor_id, embeddings) in enumerate(outputs.items()):\n",
    "            # clique_id, pos_id, neg_id = self.v_loader.dataset._triplet_sampling(anchor_id)\n",
    "            # val_loss[k] = self.triplet_loss(embeddings[0], outputs[pos_id][0], outputs[neg_id][0]).item()\n",
    "            # pos_ids.append(pos_id)\n",
    "            # neg_ids.append(neg_id)\n",
    "            clique_id = self.v_loader.dataset.version2clique.loc[anchor_id, \"clique\"]\n",
    "            clique_ids.append(clique_id)\n",
    "        # anchor_ids = np.stack(list(outputs.keys()))\n",
    "        preds = torch.stack(list(outputs.values()))[:, 1]\n",
    "        # self.postfix[\"val_loss\"] = val_loss.mean().item()\n",
    "        rranks, average_precisions = calculate_ranking_metrics(\n",
    "            embeddings=preds.float().numpy(), cliques=clique_ids\n",
    "        )\n",
    "        self.postfix[\"mrr\"] = rranks.mean()\n",
    "        self.postfix[\"mAP\"] = average_precisions.mean()\n",
    "        return {\n",
    "            # \"triplet_ids\": np.stack(list(zip(clique_ids, anchor_ids, pos_ids, neg_ids))),\n",
    "            \"rranks\": rranks,\n",
    "            \"average_precisions\": average_precisions,\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch: BatchDict) -> ValDict:\n",
    "        # print(\"start val step\")\n",
    "        anchor_id = batch[\"anchor_id\"]\n",
    "        features = self.model.forward(batch[\"anchor\"].to(dtype=torch.float,\n",
    "                                                         device=self.config[\"device\"]))\n",
    "\n",
    "        return {\n",
    "            \"anchor_id\": anchor_id.float().numpy(),\n",
    "            \"f_t\": features[\"f_t\"].float().squeeze(0).detach().cpu(),\n",
    "            \"f_c\": features[\"f_c\"].float().squeeze(0).detach().cpu(),\n",
    "        }\n",
    "\n",
    "    def test_procedure(self) -> None:\n",
    "        print(\"start test procedure\")\n",
    "        self.model.eval()\n",
    "        embeddings: Dict[str, torch.Tensor] = {}\n",
    "        trackids: List[int] = []\n",
    "        embeddings: List[np.array] = []\n",
    "        for batch in tqdm(self.test_loader, disable=(not self.config[\"progress_bar\"])):\n",
    "            test_dict = self.validation_step(batch)\n",
    "            if test_dict[\"f_c\"].ndim == 1:\n",
    "                test_dict[\"f_c\"] = test_dict[\"f_c\"].unsqueeze(0)\n",
    "            for anchor_id, embedding in zip(test_dict[\"anchor_id\"], test_dict[\"f_c\"]):\n",
    "                trackids.append(anchor_id)\n",
    "                embeddings.append(embedding.numpy())\n",
    "        predictions = []\n",
    "        for chunk_result in pairwise_distances_chunked(\n",
    "            embeddings, metric=\"cosine\", reduce_func=reduce_func, working_memory=100\n",
    "        ):\n",
    "            for query_indx, query_nearest_items in chunk_result:\n",
    "                predictions.append(\n",
    "                    (\n",
    "                        trackids[query_indx],\n",
    "                        [trackids[nn_indx] for nn_indx in query_nearest_items],\n",
    "                    )\n",
    "                )\n",
    "        print(\"saving test....\")\n",
    "        save_test_predictions(predictions, output_dir=self.config[\"test\"][\"output_dir\"])\n",
    "\n",
    "    def overfit_check(self) -> None:\n",
    "        print(\"overfit_check\")\n",
    "\n",
    "        # drive_model_path = \"models\"\n",
    "        # self.best_model_path = os.path.join(drive_model_path, f\"best-models_16_{str(uuid.uuid4())}.pt\")\n",
    "\n",
    "        # torch.save(deepcopy(self.model.state_dict()), self.best_model_path)\n",
    "\n",
    "#         for file in os.listdir(drive_model_path):\n",
    "\n",
    "#             filename = os.path.join(drive_model_path, file)\n",
    "#             if filename != self.best_model_path:\n",
    "#                 try:\n",
    "#                     os.remove(filename)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"The file {e} does not exist\")\n",
    "\n",
    "\n",
    "        if self.early_stop(self.postfix[\"mAP\"]):\n",
    "            print(\n",
    "                f\"\\nValidation not improved for {self.early_stop.patience} consecutive epochs. Stopping...\"\n",
    "            )\n",
    "            self.state = \"early_stopped\"\n",
    "\n",
    "        if self.early_stop.counter > 0:\n",
    "            print(\"\\nValidation mAP was not improved\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"\\nMetric improved. New best score: {self.early_stop.max_validation_mAP:.3f}\"\n",
    "            )\n",
    "\n",
    "            # print(\"Saving models...\")\n",
    "            # epoch = self.postfix[\"Epoch\"]\n",
    "            # max_secs = self.max_len\n",
    "            # prev_model = deepcopy(self.best_model_path)\n",
    "            #### Оригинал\n",
    "            # self.best_model_path = os.path.join(\n",
    "            #     self.config[\"val\"][\"output_dir\"],\n",
    "            #     \"models\",\n",
    "            #     f\"best-models-{epoch=}-{max_secs=}.pt\",\n",
    "            # )\n",
    "            # os.makedirs(os.path.dirname(self.best_model_path), exist_ok=True)\n",
    "            # torch.save(deepcopy(self.model.state_dict()), self.best_model_path)\n",
    "\n",
    "\n",
    "            # if prev_model is not None:\n",
    "            #     os.remove(prev_model)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.config[\"train\"][\"learning_rate\"]\n",
    "        )\n",
    "\n",
    "\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 308322,
     "status": "ok",
     "timestamp": 1730752284439,
     "user": {
      "displayName": "Ilya Ya",
      "userId": "03342033783933917263"
     },
     "user_tz": -180
    },
    "id": "kKfXgWwJmFUu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0db544f9-f113-4e2b-a85b-772ca890b0d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-9e5ddc4b731a>:60: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(\n",
      "<ipython-input-20-9e5ddc4b731a>:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(self.config[\"test\"][\"model_ckpt\"], map_location=torch.device(self.config[\"device\"])), strict=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from checkpoint: /content/drive/MyDrive/yandex_ml_olimp/models/best-resnet18_e4344df2-ae4e-42f1-a1ba-9f52f0740816.pt\n",
      "start test procedure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1725/1725 [01:05<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving test....\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "config = load_config(config_path=\"/content/drive/MyDrive/yandex_ml_olimp/config/config_colab_2.yaml\")\n",
    "\n",
    "trainer = TrainModule(config)\n",
    "# trainer.pipeline()\n",
    "trainer.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
